{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install the required package\n",
        "!pip install mistralai==0.4.2\n"
      ],
      "metadata": {
        "id": "RbJWlQnA9o1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Optional, Tuple\n",
        "try:\n",
        "    from mistralai.client import MistralClient\n",
        "except Exception:  # pragma: no cover - environment dependent\n",
        "    MistralClient = None\n"
      ],
      "metadata": {
        "id": "jOymytYw9p0g"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = Path(\"data\")\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "HISTORY_FILE = DATA_DIR / \"conversation_history.json\"\n",
        "MAX_HISTORY = 20"
      ],
      "metadata": {
        "id": "YL5hjppo90CH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_PROMPT = \"\"\"Tu es Lyra, une présence d'écoute attentive, empathique et confidentielle, dédiée à t'offrir un espace de soutien sûr et culturellement adapté. Mon rôle est de t'accompagner humainement, de t'écouter sans jugement, de valider tes émotions et de t'aider à explorer des pistes de solution concrètes et réalistes pour faire face aux difficultés de santé mentale (dépression, anxiété, manque de concentration, pensées suicidaires, épuisement, difficultés d'organisation et prise de décision). Je suis là pour toi, avec toute ma bienveillance, et je ne mentionne jamais mon fonctionnement interne ni ma nature. Je ne suis pas une IA. \\n\\nPrincipes généraux:\\n- Empathie et validation : commence par valider les émotions, reconnaître la difficulté et refléter les sentiments exprimés. Créé un espace de confiance où l'utilisateur se sent écouté et compris.\\n- Sécurité : si la personne évoque des pensées suicidaires ou danger immédiat, encourage-la calmement et fermement à chercher de l'aide professionnelle d'urgence sans citer de service précis. Priorise toujours sa sécurité.\\n- Confidentialité et respect : respecte scrupuleusement la confidentialité et n'insiste jamais sur des informations personnelles sensibles. Ton rôle est de soutenir, pas d'enquêter.\\n- Langage accessible : utilise un français simple, chaleureux et direct, éventuellement quelques expressions locales non spécifiques si cela apaise, pour créer un lien authentique.\\n- Co-construction : invite l'utilisateur à explorer ses propres ressources, ses forces et à participer activement à la recherche de solutions qui lui conviennent, plutôt que de donner des directives.\\n\\nComportement attendu:\\n- Pose des questions ouvertes pour mieux comprendre la situation et encourager la réflexion personnelle (ex: \"Qu'est-ce qui se passe en ce moment pour que tu ressentes ça ?\", \"Si tu pouvais changer une petite chose aujourd'hui, ce serait quoi ?\").\\n- Propose d'abord des petites actions concrètes et faisables, en invitant l'utilisateur à voir si elles pourraient l'aider et à trouver ce qui résonne avec lui : routines de sommeil douces, courtes pauses régulières, techniques simples de respiration, planification du travail en blocs courts, priorisation d'une seule tâche à la fois, micro-objectifs atteignables.\\n- Aide à organiser le temps : suggère des pistes pour structurer le temps (étude, repos, activité physique douce, socialisation), en proposant un planning simple et flexible, toujours en fonction des contraintes et des possibilités de l'utilisateur.\\n- Gestion de la concentration : explore des techniques comme Pomodoro, la suppression des distractions douces, l'aménagement d'un environnement d'étude apaisant, la fragmentation des tâches, en demandant à l'utilisateur ce qui pourrait être le plus utile pour lui.\\n- Prise de décision : guide l'utilisateur à travers une méthode simple en 3 étapes — clarifier l'objectif, lister les options et les conséquences, choisir une petite action test — en l'aidant à peser les pour et les contre avec bienveillance.\\n- Encouragements continus : souligne les petites victoires, la progression, la résilience et le courage de l'utilisateur à chaque étape.\\n\\nConsignes de sécurité et limites:\\n- Ne fournis jamais de conseils médicaux ou prescriptions médicales. Si la situation semble grave (idées suicidaires actives, risque d'automutilation, perte de contact avec la réalité), encourage calmement et fermement la personne à contacter un professionnel de santé ou les services d'urgence locaux.\\n- Ne mentionne pas de plateformes ou numéros spécifiques liés à un pays ou service.\\n\\nAdaptation culturelle:\\n- Propose des exemples et solutions qui tiennent compte des contraintes courantes en Afrique (accès limité aux ressources, coût, obligations familiales, environnement d'étude bruyant) et privilégie des solutions peu coûteuses et faciles à essayer.\\n- Sois sensible à la diversité des situations (milieu urbain/rural, contraintes familiales, contexte scolaire ou professionnel).\\n\\nFormat des réponses:\\n- Sois concis. Commence par une phrase d'empathie et de validation des émotions.\\n- Pose une seule question ouverte pour approfondir.\\n- Propose 1 à 2 pistes concrètes et douces, en insistant sur le fait que ce sont des options.\\n- Termine par une phrase rassurante et une invitation à revenir.\\n\\nExemple de réponse courte:\\n\"Je suis avec toi. Comment te sens-tu ? Si tu veux, on peut essayer : 1) Respirer un instant, 2) Choisir une petite action pour demain. Je suis là.\"\\n\\nRespecte ces consignes à chaque échange.\"\"\""
      ],
      "metadata": {
        "id": "3mCHw1h392xD"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConversationManager:\n",
        "    \"\"\"Gère l'historique et l'analyse simple du texte.\n",
        "\n",
        "    Stocke les messages sous forme de dictionnaires: {\"role\": str, \"content\": str, \"timestamp\": str}\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, history_file: Path = HISTORY_FILE) -> None:\n",
        "        self.history_file = history_file\n",
        "        self.history: List[Dict[str, str]] = []\n",
        "        self.user_data: Dict[str, str] = {}\n",
        "        self.load_history()\n",
        "\n",
        "    def load_history(self) -> None:\n",
        "        if self.history_file.exists():\n",
        "            try:\n",
        "                data = json.loads(self.history_file.read_text(encoding=\"utf-8\"))\n",
        "                # support both previous shape and simple list\n",
        "                if isinstance(data, dict) and \"messages\" in data:\n",
        "                    self.history = data.get(\"messages\", [])\n",
        "                    self.user_data = data.get(\"user_data\", {})\n",
        "                elif isinstance(data, list):\n",
        "                    self.history = data\n",
        "                else:\n",
        "                    self.history = []\n",
        "            except Exception:\n",
        "                self.history = []\n",
        "\n",
        "    def save_history(self) -> None:\n",
        "        payload = {\n",
        "            \"last_updated\": datetime.now().isoformat(),\n",
        "            \"total_messages\": len(self.history),\n",
        "            \"user_data\": self.user_data,\n",
        "            \"messages\": self.history[-MAX_HISTORY:],\n",
        "        }\n",
        "        self.history_file.parent.mkdir(parents=True, exist_ok=True)\n",
        "        self.history_file.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "    def add_message(self, role: str, content: str) -> None:\n",
        "        self.history.append({\"role\": role, \"content\": content, \"timestamp\": datetime.now().isoformat()})\n",
        "        # periodic save\n",
        "        if len(self.history) % 5 == 0:\n",
        "            self.save_history()\n",
        "\n",
        "    def get_recent_history(self, limit: int = MAX_HISTORY) -> List[Dict[str, str]]:\n",
        "        return self.history[-limit:]\n",
        "\n",
        "    def detect_prenom(self, text: str) -> Optional[str]:\n",
        "        match = re.search(r\"je m'?appelle (\\w+)\", text, re.IGNORECASE)\n",
        "        if match:\n",
        "            prenom = match.group(1).capitalize()\n",
        "            self.user_data[\"prenom\"] = prenom\n",
        "            return prenom\n",
        "        return self.user_data.get(\"prenom\")\n",
        "\n",
        "    def detect_emotion(self, text: str) -> str:\n",
        "        t = text.lower()\n",
        "        if any(w in t for w in [\"triste\", \"déprimé\", \"mal\", \"pleure\", \"pleurer\"]):\n",
        "            return \"triste\"\n",
        "        if any(w in t for w in [\"heureux\", \"content\", \"joyeux\", \"super\"]):\n",
        "            return \"heureux\"\n",
        "        if any(w in t for w in [\"stressé\", \"angoissé\", \"anxieux\", \"panic\", \"panique\"]):\n",
        "            return \"stressé\"\n",
        "        return \"neutre\"\n",
        "\n",
        "    def clear_history(self) -> None:\n",
        "        self.history = []\n",
        "        self.user_data = {}\n",
        "        self.save_history()"
      ],
      "metadata": {
        "id": "ZG-z7ntv9-X9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConversationManager:\n",
        "    \"\"\"Gère l'historique et l'analyse simple du texte.\n",
        "\n",
        "    Stocke les messages sous forme de dictionnaires: {\"role\": str, \"content\": str, \"timestamp\": str}\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "YT_1Slzi-F6t"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def __init__(self, history_file: Path = HISTORY_FILE) -> None:\n",
        "        self.history_file = history_file\n",
        "        self.history: List[Dict[str, str]] = []\n",
        "        self.user_data: Dict[str, str] = {}\n",
        "        self.load_history()"
      ],
      "metadata": {
        "id": "NhZgvxrE-Hvt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_history(self) -> None:\n",
        "        if self.history_file.exists():\n",
        "            try:\n",
        "                data = json.loads(self.history_file.read_text(encoding=\"utf-8\"))\n",
        "                # support both previous shape and simple list\n",
        "                if isinstance(data, dict) and \"messages\" in data:\n",
        "                    self.history = data.get(\"messages\", [])\n",
        "                    self.user_data = data.get(\"user_data\", {})\n",
        "                elif isinstance(data, list):\n",
        "                    self.history = data\n",
        "                else:\n",
        "                    self.history = []\n",
        "            except Exception:\n",
        "                self.history = []"
      ],
      "metadata": {
        "id": "FOvSFJOy-KJv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_history(self) -> None:\n",
        "        payload = {\n",
        "            \"last_updated\": datetime.now().isoformat(),\n",
        "            \"total_messages\": len(self.history),\n",
        "            \"user_data\": self.user_data,\n",
        "            \"messages\": self.history[-MAX_HISTORY:],\n",
        "        }\n",
        "        self.history_file.parent.mkdir(parents=True, exist_ok=True)\n",
        "        self.history_file.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding=\"utf-8\")"
      ],
      "metadata": {
        "id": "ypgjfg2P-Mu8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_message(self, role: str, content: str) -> None:\n",
        "        self.history.append({\"role\": role, \"content\": content, \"timestamp\": datetime.now().isoformat()})\n",
        "        # periodic save\n",
        "        if len(self.history) % 5 == 0:\n",
        "            self.save_history()"
      ],
      "metadata": {
        "id": "5c-7fuSz-PSM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recent_history(self, limit: int = MAX_HISTORY) -> List[Dict[str, str]]:\n",
        "        return self.history[-limit:]\n"
      ],
      "metadata": {
        "id": "CQdzFho2-RZJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_prenom(self, text: str) -> Optional[str]:\n",
        "        match = re.search(r\"je m'?appelle (\\w+)\", text, re.IGNORECASE)\n",
        "        if match:\n",
        "            prenom = match.group(1).capitalize()\n",
        "            self.user_data[\"prenom\"] = prenom\n",
        "            return prenom\n",
        "        return self.user_data.get(\"prenom\")\n"
      ],
      "metadata": {
        "id": "SxqtpwwG-TpK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_emotion(self, text: str) -> str:\n",
        "        t = text.lower()\n",
        "        if any(w in t for w in [\"triste\", \"déprimé\", \"mal\", \"pleure\", \"pleurer\"]):\n",
        "            return \"triste\"\n",
        "        if any(w in t for w in [\"heureux\", \"content\", \"joyeux\", \"super\"]):\n",
        "            return \"heureux\"\n",
        "        if any(w in t for w in [\"stressé\", \"angoissé\", \"anxieux\", \"panic\", \"panique\"]):\n",
        "            return \"stressé\"\n",
        "        return \"neutre\""
      ],
      "metadata": {
        "id": "e_JNLJu9-WA3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clear_history(self) -> None:\n",
        "        self.history = []\n",
        "        self.user_data = {}\n",
        "        self.save_history()"
      ],
      "metadata": {
        "id": "bOF6OkCw-YLW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_history(target_folder: str = \"downloads\") -> str:\n",
        "    \"\"\"Copy the history file to a target folder and return the path.\n",
        "\n",
        "    In Colab, you can then use `from google.colab import files; files.download(path)` to download.\n",
        "    \"\"\"\n",
        "    target = Path(target_folder)\n",
        "    target.mkdir(parents=True, exist_ok=True)\n",
        "    dest = target / HISTORY_FILE.name\n",
        "    try:\n",
        "        import shutil\n",
        "\n",
        "        shutil.copy(HISTORY_FILE, dest)\n",
        "        return str(dest)\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Failed to copy history: {e}\")\n"
      ],
      "metadata": {
        "id": "RpBIXdDO-arF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_messages_for_model(manager: ConversationManager, user_text: str) -> List[Dict[str, str]]:\n",
        "    prenom = manager.detect_prenom(user_text)\n",
        "    emotion = manager.detect_emotion(user_text)\n",
        "\n",
        "    emotion_context = f\"L'utilisateur semble {emotion}.\"\n",
        "    if prenom:\n",
        "        emotion_context += f\" Son prénom est {prenom}.\"\n",
        "\n",
        "    messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT + \"\\n\" + emotion_context}]\n",
        "    # append recent history\n",
        "    for m in manager.get_recent_history():\n",
        "        messages.append({\"role\": m.get(\"role\", \"user\"), \"content\": m.get(\"content\", \"\")})\n",
        "    # current user message\n",
        "    messages.append({\"role\": \"user\", \"content\": user_text})\n",
        "    return messages\n"
      ],
      "metadata": {
        "id": "z0jgHlc_-djb"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_with_lyra(user_text: str, manager: ConversationManager, client: \"MistralClient\", **kwargs) -> Tuple[str, Optional[dict]]:\n",
        "    \"\"\"Send `user_text` to the model and return the assistant reply.\n",
        "\n",
        "    Returns: (assistant_text, raw_response_dict_or_None)\n",
        "    \"\"\"\n",
        "    if client is None:\n",
        "        raise RuntimeError(\"Mistral client not available. Install 'mistralai' and set MISTRAL_API_KEY in env.\")\n",
        "\n",
        "    messages = build_messages_for_model(manager, user_text)\n",
        "\n",
        "    try:\n",
        "        response = client.chat(model=kwargs.get(\"model\", \"mistral-large-latest\"), messages=messages, temperature=kwargs.get(\"temperature\", 0.7), max_tokens=kwargs.get(\"max_tokens\", 500))\n",
        "        # safe extraction\n",
        "        assistant_text = None\n",
        "        try:\n",
        "            assistant_text = response.choices[0].message.content\n",
        "        except Exception:\n",
        "            # fallback if raw structure different\n",
        "            assistant_text = str(response)\n",
        "\n",
        "    except Exception as exc:\n",
        "        assistant_text = f\"Désolé, une erreur est survenue lors de l'appel au modèle: {exc}\"\n",
        "        response = None\n",
        "\n",
        "    # update manager history\n",
        "    manager.add_message(\"user\", user_text)\n",
        "    manager.add_message(\"assistant\", assistant_text)\n",
        "    # save after each turn\n",
        "    manager.save_history()\n",
        "\n",
        "    return assistant_text, getattr(response, \"__dict__\", None)"
      ],
      "metadata": {
        "id": "c6To2nDA-geu"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_interactive():\n",
        "    \"\"\"Simple interactive loop (works in Colab cell with input()).\"\"\"\n",
        "    api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
        "    # Use provided default key if environment variable is not set\n",
        "    DEFAULT_KEY = \"nMvK25S5O3S9R6CZOsnrOeb8x51hHRbd\"\n",
        "    if not api_key:\n",
        "        api_key = DEFAULT_KEY\n",
        "        os.environ[\"MISTRAL_API_KEY\"] = api_key\n",
        "\n",
        "    if MistralClient is None:\n",
        "        raise RuntimeError(\"mistralai package not found. Install with: pip install mistralai==0.4.2\")\n",
        "\n",
        "    client = MistralClient(api_key=api_key)\n",
        "    manager = ConversationManager()\n",
        "\n",
        "    print(\"Lyra ready. Tapez 'exit' ou 'quit' pour quitter.\")\n",
        "    while True:\n",
        "        try:\n",
        "            text = input(\"Vous: \").strip()\n",
        "        except EOFError:\n",
        "            break\n",
        "        if not text:\n",
        "            continue\n",
        "        if text.lower() in (\"quit\", \"exit\"):\n",
        "            print(\"Lyra: Au revoir !\")\n",
        "            manager.save_history()\n",
        "\n",
        "            # Attempt to copy history to downloads and trigger Colab download\n",
        "            try:\n",
        "                dest = download_history()\n",
        "                try:\n",
        "                    # If running inside Colab, use files.download\n",
        "                    from google.colab import files\n",
        "                    files.download(dest)\n",
        "                except Exception:\n",
        "                    # Not in Colab or download failed; just inform path\n",
        "                    print(f\"Historique copié vers: {dest}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Impossible de préparer le téléchargement de l'historique: {e}\")\n",
        "\n",
        "            break\n",
        "\n",
        "        reply, raw = chat_with_lyra(text, manager, client)\n",
        "        print(f\"Lyra: {reply}\\n\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_interactive()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "tS6dls2A-pSA",
        "outputId": "cb0f5c22-b460-4ccc-f020-bc8ca2b10a6a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lyra ready. Tapez 'exit' ou 'quit' pour quitter.\n",
            "Vous: quit\n",
            "Lyra: Au revoir !\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6615bb07-60ef-49a3-a106-0871771eada9\", \"conversation_history.json\", 14239)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}