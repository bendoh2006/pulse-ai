# Architecture Backend â€” Documentation Technique

## ğŸ“‹ Vue d'Ensemble

Le backend PulseAI est une API REST construite avec **FastAPI** qui expose deux services principaux :
1. **Diagnostic System** (RuralDiag) â€” RAG + FAISS
2. **Lyra Service** â€” Assistant mental virtuel

---

## ğŸ—ï¸ Architecture Globale

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         FastAPI Application             â”‚
â”‚         (app/main.py)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Diagnostic â”‚   â”‚     Lyra      â”‚  â”‚
â”‚  â”‚   Service    â”‚   â”‚   Service     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                   â”‚           â”‚
â”‚         â–¼                   â–¼           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  FAISS Index â”‚   â”‚ Conversation  â”‚  â”‚
â”‚  â”‚  RAG Corpus  â”‚   â”‚   Manager     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                   â”‚           â”‚
â”‚         â–¼                   â–¼           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Mistral API  â”‚   â”‚ Mistral API   â”‚  â”‚
â”‚  â”‚ (Diagnosis)  â”‚   â”‚  (Chat)       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‚ Structure des Fichiers

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                  # Point d'entrÃ©e FastAPI
â”‚   â”œâ”€â”€ diagnostic_service.py    # Service RAG + FAISS
â”‚   â””â”€â”€ lyra_service.py          # Service Lyra (chat)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ rag_clean.csv            # Corpus mÃ©dical structurÃ©
â”‚   â”œâ”€â”€ rag_index.faiss          # Index vectoriel FAISS
â”‚   â”œâ”€â”€ rag_docs.pkl             # Documents sÃ©rialisÃ©s
â”‚   â””â”€â”€ sessions/                # Sessions de chat persistÃ©es
â”œâ”€â”€ prompts/
â”‚   â””â”€â”€ lyra_system_prompt.txt   # Prompt systÃ¨me Lyra
â”œâ”€â”€ Dockerfile                   # Conteneurisation
â”œâ”€â”€ render.yaml                  # Config dÃ©ploiement Render
â”œâ”€â”€ requirements.txt             # DÃ©pendances Python
â””â”€â”€ test_backend.py              # Tests unitaires
```

---

## ğŸ”Œ API Endpoints

### Health Check
```http
GET /
Response: {"status": "healthy", "version": "2.0.0"}
```

### Diagnostic Service (RuralDiag)

#### 1. Liste des SymptÃ´mes
```http
GET /diagnostic/symptoms
Response: {
  "symptoms": ["FiÃ¨vre", "Maux de tÃªte", ...]
}
```

#### 2. Analyse de Diagnostic
```http
POST /diagnostic/analyze
Body: {
  "symptoms": ["FiÃ¨vre", "Toux"],
  "notes": "SymptÃ´mes depuis 3 jours",
  "user_id": "user123"
}
Response: {
  "diagnosis": "Analyse dÃ©taillÃ©e...",
  "recommendations": [...],
  "severity": "moderate"
}
```

### Lyra Service (Assistant Mental)

#### 1. CrÃ©er Session
```http
POST /lyra/create_session
Body: {
  "user_id": "user123"
}
Response: {
  "session_id": "uuid-xxx"
}
```

#### 2. Chat
```http
POST /lyra/chat
Body: {
  "session_id": "uuid-xxx",
  "message": "Je me sens stressÃ©"
}
Response: {
  "response": "Je comprends que tu te sentes stressÃ©...",
  "session_id": "uuid-xxx"
}
```

#### 3. Historique
```http
GET /lyra/history/{session_id}
Response: {
  "messages": [
    {"role": "user", "content": "...", "timestamp": "..."},
    {"role": "assistant", "content": "...", "timestamp": "..."}
  ]
}
```

---

## ğŸ§  Diagnostic Service â€” Architecture RAG

### Composants

#### 1. **Embedding Model**
```python
SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")
```
- Convertit le texte en vecteurs de 384 dimensions
- Lazy loading (chargÃ© Ã  la premiÃ¨re utilisation)
- OptimisÃ© pour recherche sÃ©mantique

#### 2. **FAISS Index**
```python
faiss.IndexFlatL2(384)
```
- Recherche vectorielle par similaritÃ© L2
- Chargement paresseux pour performance
- RequÃªtes en < 50ms pour 10K+ documents

#### 3. **RAG Pipeline**
```
User Input (symptÃ´mes + notes)
        â†“
Embedding (SentenceTransformer)
        â†“
FAISS Search (top-k docs similaires)
        â†“
Context Building (docs + symptÃ´mes)
        â†“
Mistral API (gÃ©nÃ©ration diagnostic)
        â†“
Response (diagnosis + recommendations)
```

### Fonctions ClÃ©s

#### `_load_symptoms()`
Charge la liste des symptÃ´mes depuis `rag_clean.csv`.

#### `_ensure_index_loaded()`
Charge l'index FAISS et l'embedder (lazy loading).

#### `_retrieve_context(query: str, top_k: int) -> List[Dict]`
Recherche les documents les plus pertinents via FAISS.

#### `generate_diagnosis(symptoms: List[str], notes: str) -> Dict`
GÃ©nÃ¨re un diagnostic complet avec :
- Analyse des symptÃ´mes
- Contexte mÃ©dical (RAG)
- Recommandations
- Niveau de sÃ©vÃ©ritÃ©

### Exemple de Flux

```python
# 1. Utilisateur sÃ©lectionne symptÃ´mes
symptoms = ["FiÃ¨vre", "Toux sÃ¨che", "Fatigue"]
notes = "Depuis 3 jours, tempÃ©rature 38.5Â°C"

# 2. Construction de la requÃªte
query = "SymptÃ´mes: FiÃ¨vre, Toux sÃ¨che, Fatigue. Notes: Depuis 3 jours..."

# 3. Embedding
query_vector = embedder.encode([query])

# 4. Recherche FAISS (top-3 documents)
distances, indices = index.search(query_vector, k=3)
relevant_docs = [docs[i] for i in indices[0]]

# 5. Construction du contexte
context = "\n".join([doc["content"] for doc in relevant_docs])

# 6. Prompt Mistral API
prompt = f"""
Contexte mÃ©dical:
{context}

Patient:
- SymptÃ´mes: {', '.join(symptoms)}
- Notes: {notes}

GÃ©nÃ¨re un diagnostic informatif et des recommandations.
"""

# 7. GÃ©nÃ©ration
response = mistral_client.chat(messages=[{"role": "user", "content": prompt}])
```

---

## ğŸ’¬ Lyra Service â€” Architecture

### Composants

#### 1. **ConversationManager**
```python
class ConversationManager:
    - history: List[Dict[str, str]]  # Messages historiques
    - user_data: Dict[str, str]       # DonnÃ©es utilisateur
    - history_file: Path              # Fichier de persistence
```

GÃ¨re :
- Persistence des conversations (JSON)
- Limitation Ã  20 derniers messages (performance)
- DÃ©tection de patterns (Ã©motions basiques)

#### 2. **System Prompt**
ChargÃ© depuis `prompts/lyra_system_prompt.txt` :
```
Tu es Lyra, un assistant virtuel empathique...
RÃˆGLES STRICTES:
- N'utilise JAMAIS d'astÃ©risques, Markdown
- EXCLUSIVEMENT tutoiement (tu/toi)
- NumÃ©rote avec 1) 2) 3)
- Ne mentionne jamais Mistral
```

#### 3. **Session Management**
- Chaque utilisateur a un `session_id` unique
- Sessions stockÃ©es dans `data/sessions/{session_id}.json`
- Auto-crÃ©ation si inexistante

### Fonctions ClÃ©s

#### `create_session(user_id: str) -> str`
CrÃ©e une nouvelle session de chat.

#### `chat_with_lyra(session_id: str, message: str) -> Dict`
Envoie un message et retourne la rÃ©ponse de Lyra.

#### `get_history(session_id: str) -> List[Dict]`
RÃ©cupÃ¨re l'historique d'une session.

### Exemple de Flux

```python
# 1. CrÃ©er session
session_id = create_session("user123")

# 2. Chat
response = chat_with_lyra(
    session_id=session_id,
    message="Je me sens stressÃ© par mes examens"
)
# Response: {
#   "response": "Je comprends que la pÃ©riode d'examens...",
#   "session_id": "uuid-xxx"
# }

# 3. Historique
history = get_history(session_id)
# [
#   {"role": "user", "content": "Je me sens...", "timestamp": "..."},
#   {"role": "assistant", "content": "Je comprends...", "timestamp": "..."}
# ]
```

---

## ğŸ³ DÃ©ploiement

### Docker

```dockerfile
FROM python:3.10-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY . .
EXPOSE 8000
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

Build & Run :
```bash
docker build -t pulseai-backend .
docker run -p 8000:8000 --env-file .env pulseai-backend
```

### Render

Configuration dans `render.yaml` :
```yaml
services:
  - type: web
    name: pulseai-backend
    env: docker
    plan: free
    envVars:
      - key: MISTRAL_API_KEY
        sync: false
```

Deploy :
```bash
git push origin main  # Auto-deploy via Render
```

---

## ğŸ§ª Tests

### ExÃ©cution
```bash
pytest backend/test_backend.py -v
```

### Couverture
```bash
pytest --cov=backend/app --cov-report=html
```

### Tests Disponibles
- âœ… Health check
- âœ… Liste des symptÃ´mes
- âœ… Diagnostic avec symptÃ´mes valides
- âœ… Session Lyra
- âœ… Chat Lyra
- âœ… Historique Lyra

---

## âš¡ Performance

### Optimisations

1. **Lazy Loading**
   - Embedder chargÃ© uniquement Ã  la premiÃ¨re utilisation
   - FAISS index chargÃ© Ã  la demande

2. **Caching**
   - Embedder gardÃ© en mÃ©moire aprÃ¨s chargement
   - Index FAISS persistÃ© en RAM

3. **Garbage Collection**
   - Nettoyage mÃ©moire aprÃ¨s opÃ©rations lourdes

### Benchmarks

| Endpoint | Temps Moyen | MÃ©moire |
|----------|-------------|---------|
| GET /diagnostic/symptoms | < 10ms | ~50MB |
| POST /diagnostic/analyze | ~1-2s | ~300MB |
| POST /lyra/chat | ~500ms-1s | ~100MB |

---

## ğŸ” SÃ©curitÃ©

### Best Practices

1. **Variables d'Environnement**
   - Secrets dans `.env` (jamais commitÃ©es)
   - Validation au dÃ©marrage

2. **CORS**
   - Origins whitelistÃ©s
   - Regex pattern pour domaines dynamiques

3. **Validation EntrÃ©es**
   - Pydantic models pour toutes les requÃªtes
   - Sanitization des inputs utilisateurs

4. **Rate Limiting** (Ã€ ImplÃ©menter)
   ```python
   from slowapi import Limiter
   limiter = Limiter(key_func=get_remote_address)
   @limiter.limit("10/minute")
   ```

---

## ğŸ“Š Monitoring & Logs

### Logs StructurÃ©s
```python
import logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
```

### MÃ©triques Ã  Surveiller
- Latence API (p50, p95, p99)
- Taux d'erreur Mistral API
- MÃ©moire FAISS index
- Sessions actives Lyra

---

## ğŸ”§ DÃ©pendances Principales

```txt
fastapi==0.104.1         # Framework API
uvicorn==0.24.0          # Serveur ASGI
sentence-transformers    # Embeddings
faiss-cpu==1.7.4         # Vector search
mistralai                # LLM API
pydantic==2.5.0          # Validation
```

---

## ğŸš€ Roadmap Technique

- [ ] Rate limiting (SlowAPI)
- [ ] Cache Redis pour embeddings frÃ©quents
- [ ] Websockets pour chat temps rÃ©el
- [ ] MÃ©triques Prometheus
- [ ] Tests de charge (Locust)
- [ ] CI/CD avec GitHub Actions
- [ ] Monitoring Sentry

---

## ğŸ‘¨â€ğŸ’» Contribution au Code

Consultez [CONTRIBUTING.md](../CONTRIBUTING.md) pour :
- Conventions de code (PEP 8)
- Workflow Git (feature branches)
- Standards de tests
- Review process
